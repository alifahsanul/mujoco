{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import mediapy as media\n",
    "\n",
    "import mujoco\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import importlib\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_vars = util.load_json_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"show_images\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><img width=\"320\" height=\"240\" style=\"image-rendering:auto; object-fit:cover;\" src=\"data:image/png;base64,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\"/></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xml_path = \"2dof_robot.xml\"\n",
    "\n",
    "# Read the XML content from the file\n",
    "with open(xml_path, 'r') as file:\n",
    "    my_robot_xml = file.read()\n",
    "model = mujoco.MjModel.from_xml_string(my_robot_xml)\n",
    "data = mujoco.MjData(model)\n",
    "height = 480\n",
    "width = 640\n",
    "\n",
    "\n",
    "with mujoco.Renderer(model) as renderer:\n",
    "  mujoco.mj_forward(model, data)\n",
    "  renderer.update_scene(data)\n",
    "  media.show_image(renderer.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try testing randomizing ball position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179.63554396909643 5.39320092946092 113.06695247011977 -139.58793972329002\n",
      "Original ball position: [-100. -120.  150.]\n",
      "New ball position: [np.float64(113.06695247011977), np.float64(-139.58793972329002)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"show_images\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><img width=\"320\" height=\"240\" style=\"image-rendering:auto; object-fit:cover;\" src=\"data:image/png;base64,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\"/></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import util\n",
    "\n",
    "importlib.reload(util)\n",
    "\n",
    "# Read the XML content from the file\n",
    "with open(xml_path, 'r') as file:\n",
    "    my_robot_xml = file.read()\n",
    "model = mujoco.MjModel.from_xml_string(my_robot_xml)\n",
    "util.randomize_ball_position(model, json_vars, seed=None, print_info=True)\n",
    "data = mujoco.MjData(model)\n",
    "height = 480\n",
    "width = 640\n",
    "\n",
    "\n",
    "with mujoco.Renderer(model) as renderer:\n",
    "  mujoco.mj_forward(model, data)\n",
    "  renderer.update_scene(data, camera='my_camera')\n",
    "  media.show_image(renderer.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use dummy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robot_env\n",
    "import training_module\n",
    "\n",
    "importlib.reload(robot_env)\n",
    "importlib.reload(training_module)\n",
    "importlib.reload(util)\n",
    "\n",
    "\n",
    "# Define a dummy policy that always outputs the same action value\n",
    "class DummyPolicy:\n",
    "    def __init__(self, action_value):\n",
    "        self.action_value = action_value\n",
    "\n",
    "    def predict(self, obs):\n",
    "        return self.action_value, None\n",
    "\n",
    "dummy_policy = DummyPolicy(action_value=np.array([1, 0]))\n",
    "env = robot_env.ArmEnv(model_path='2dof_robot.xml')\n",
    "obs, _ = env.reset()\n",
    "\n",
    "frames = []\n",
    "# Simulate for a few seconds\n",
    "for _ in range(100):\n",
    "    action, _ = dummy_policy.predict(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    frame = env.render(mode='rgb_array')\n",
    "    text_list = [\n",
    "                f'Step: {info[\"current_step\"]}',\n",
    "                f'Action: {action[0]:.2f} {action[1]:.2f}',\n",
    "                f'distance: {info[\"distance\"]:.4f}',\n",
    "                f'qvel: {info[\"qvel\"][0]:.2f} {info[\"qvel\"][1]:.2f}',\n",
    "                f'Arm Tip XYZ: {info[\"arm2_tip_pos\"][0]:.2f} {info[\"arm2_tip_pos\"][1]:.2f} {info[\"arm2_tip_pos\"][2]:.2f}',\n",
    "                f'Ball XYZ: {info[\"ball_pos\"][0]:.2f} {info[\"ball_pos\"][1]:.2f} {info[\"ball_pos\"][2]:.2f}',\n",
    "                f'done: {done}',\n",
    "                f'reward: {reward:.2f}',\n",
    "                f'is_success: {info[\"is_success\"]}'\n",
    "                ]\n",
    "    frames.append(util.add_text_frame(text_list, frame))\n",
    "    # print(f\"Step: {info['current_step']}, Action: {action}, Reward: {reward}, Done: {done}\")\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# media.show_video(frames, fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using RL to learn policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new model\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./ppo_logs/PPO_13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1171 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 256  |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1026         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 0            |\n",
      "|    total_timesteps      | 512          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022363137 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -6.81e-05    |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.17e+05     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.36e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 963           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 0             |\n",
      "|    total_timesteps      | 768           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00056671794 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | -4.23e-05     |\n",
      "|    learning_rate        | 0.001         |\n",
      "|    loss                 | 1.51e+05      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00126      |\n",
      "|    std                  | 0.992         |\n",
      "|    value_loss           | 2.92e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 966          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 1024         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012732365 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | -1.91e-06    |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 2.02e+05     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 4.13e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 954          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 1280         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010759032 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | 0.000234     |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 2.97e+05     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 5.7e+05      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 954           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 1             |\n",
      "|    total_timesteps      | 1536          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035821367 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.81         |\n",
      "|    explained_variance   | 0.000525      |\n",
      "|    learning_rate        | 0.001         |\n",
      "|    loss                 | 2.77e+05      |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.000885     |\n",
      "|    std                  | 0.989         |\n",
      "|    value_loss           | 5.75e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 947          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 1792         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013491313 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.000523     |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 2.99e+05     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 6e+05        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | -7.54e+04     |\n",
      "|    success_rate         | 0             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 944           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 2             |\n",
      "|    total_timesteps      | 2048          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6704587e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.00025       |\n",
      "|    learning_rate        | 0.001         |\n",
      "|    loss                 | 3.4e+05       |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -7.64e-06     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 6.91e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | -7.54e+04    |\n",
      "|    success_rate         | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 944          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 2304         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019552682 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.000489     |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 2.79e+05     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 5.58e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | -7.54e+04    |\n",
      "|    success_rate         | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 943          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 2560         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017157884 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.91        |\n",
      "|    explained_variance   | -9.82e-05    |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.16e+05     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 2.3e+05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | -7.54e+04    |\n",
      "|    success_rate         | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 940          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 2816         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008173492 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.91        |\n",
      "|    explained_variance   | -8.82e-06    |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.43e+05     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 2.83e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | -7.54e+04    |\n",
      "|    success_rate         | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 938          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010271596 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 6.92e-05     |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.68e+05     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 3.23e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | -7.54e+04     |\n",
      "|    success_rate         | 0             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 935           |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 3328          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053194654 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.88         |\n",
      "|    explained_variance   | -6.78e-05     |\n",
      "|    learning_rate        | 0.001         |\n",
      "|    loss                 | 2.01e+05      |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.00112      |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 3.96e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | -7.54e+04    |\n",
      "|    success_rate         | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 936          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 3584         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018653609 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | -1.96e-05    |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 2.88e+05     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 5.67e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | -7.54e+04     |\n",
      "|    success_rate         | 0             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 938           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 4             |\n",
      "|    total_timesteps      | 3840          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037930417 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.88         |\n",
      "|    explained_variance   | -5.36e-06     |\n",
      "|    learning_rate        | 0.001         |\n",
      "|    loss                 | 3.74e+05      |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.000557     |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 7.67e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | -7.55e+04    |\n",
      "|    success_rate         | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 939          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.759865e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | 1.55e-05     |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 4.52e+05     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.000479    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 8.96e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | -7.55e+04   |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 936         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4352        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001207165 |\n",
      "|    clip_fraction        | 0.000781    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.0139      |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 2.76e+05    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 5.42e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | -5.11e+04    |\n",
      "|    success_rate         | 0.333        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 936          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 4608         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028011731 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.026        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.5e+04      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 2.94e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | -5.11e+04    |\n",
      "|    success_rate         | 0.333        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 936          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4864         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029519123 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.9         |\n",
      "|    explained_variance   | 0.00287      |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 8.68e+04     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 1.76e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | -5.11e+04    |\n",
      "|    success_rate         | 0.333        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 931          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012903288 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.9         |\n",
      "|    explained_variance   | 3.99e-06     |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.87e+05     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 3.76e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | -5.11e+04    |\n",
      "|    success_rate         | 0.333        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 930          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 5376         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007825345 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | -5.48e-06    |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 1.75e+05     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 3.45e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.48e+03      |\n",
      "|    ep_rew_mean          | -5.11e+04     |\n",
      "|    success_rate         | 0.333         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 921           |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 6             |\n",
      "|    total_timesteps      | 5632          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036014547 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.88         |\n",
      "|    explained_variance   | 0.000161      |\n",
      "|    learning_rate        | 0.000999      |\n",
      "|    loss                 | 2.94e+05      |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -0.000684     |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 6.26e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.48e+03      |\n",
      "|    ep_rew_mean          | -5.11e+04     |\n",
      "|    success_rate         | 0.333         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 915           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 6             |\n",
      "|    total_timesteps      | 5888          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020142505 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.88         |\n",
      "|    explained_variance   | 5.36e-06      |\n",
      "|    learning_rate        | 0.000999      |\n",
      "|    loss                 | 3.92e+05      |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.000214     |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 7.79e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.48e+03      |\n",
      "|    ep_rew_mean          | -5.11e+04     |\n",
      "|    success_rate         | 0.333         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 917           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 6             |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073926966 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.88         |\n",
      "|    explained_variance   | -4.53e-06     |\n",
      "|    learning_rate        | 0.000999      |\n",
      "|    loss                 | 4.49e+05      |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.00127      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 8.92e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | -5.11e+04    |\n",
      "|    success_rate         | 0.333        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 917          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 6400         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004143312 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | -1.67e-06    |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 4.15e+05     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.000662    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 8.02e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | -5.94e+04    |\n",
      "|    success_rate         | 0.25         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 917          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 6656         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013790529 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | 2.98e-07     |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 4.14e+05     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 8.53e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -5.94e+04   |\n",
      "|    success_rate         | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 912         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 6912        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004164862 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.0011      |\n",
      "|    learning_rate        | 0.000999    |\n",
      "|    loss                 | 5.22e+04    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.09e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -5.94e+04   |\n",
      "|    success_rate         | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 913         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005172708 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.00357     |\n",
      "|    learning_rate        | 0.000999    |\n",
      "|    loss                 | 2.36e+04    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 4.75e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | -5.94e+04    |\n",
      "|    success_rate         | 0.25         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 914          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 7424         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005767138 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.000128     |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 1.31e+05     |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 2.63e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | -5.94e+04    |\n",
      "|    success_rate         | 0.25         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 915          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 7680         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013317042 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.00156      |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 2.33e+05     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 5.05e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.61e+03      |\n",
      "|    ep_rew_mean          | -5.94e+04     |\n",
      "|    success_rate         | 0.25          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 916           |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 7936          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034422474 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.88         |\n",
      "|    explained_variance   | -0.000115     |\n",
      "|    learning_rate        | 0.000999      |\n",
      "|    loss                 | 1.13e+05      |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | -0.00125      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 2.08e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | -5.94e+04    |\n",
      "|    success_rate         | 0.25         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 918          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016918185 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.88        |\n",
      "|    explained_variance   | 0.000305     |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 1.91e+05     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 3.67e+05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.69e+03      |\n",
      "|    ep_rew_mean          | -5.9e+04      |\n",
      "|    success_rate         | 0.2           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 920           |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 8448          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071282964 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.9          |\n",
      "|    explained_variance   | 2.4e-05       |\n",
      "|    learning_rate        | 0.000999      |\n",
      "|    loss                 | 4.07e+05      |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | -0.002        |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 7.93e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.69e+03      |\n",
      "|    ep_rew_mean          | -5.9e+04      |\n",
      "|    success_rate         | 0.2           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 920           |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 8704          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040629832 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.91         |\n",
      "|    explained_variance   | -2.19e-05     |\n",
      "|    learning_rate        | 0.000999      |\n",
      "|    loss                 | 2.34e+05      |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | -0.00173      |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 4.76e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.69e+03     |\n",
      "|    ep_rew_mean          | -5.9e+04     |\n",
      "|    success_rate         | 0.2          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 921          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 8960         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028418521 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.9         |\n",
      "|    explained_variance   | 0.000349     |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 2.93e+04     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 5.78e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -5.9e+04    |\n",
      "|    success_rate         | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 922         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010910351 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | 0.000121    |\n",
      "|    learning_rate        | 0.000999    |\n",
      "|    loss                 | 1.13e+04    |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 2.21e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -5.9e+04    |\n",
      "|    success_rate         | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 921         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 9472        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002377728 |\n",
      "|    clip_fraction        | 0.00508     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | 1.91e-05    |\n",
      "|    learning_rate        | 0.000999    |\n",
      "|    loss                 | 3.39e+04    |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.52e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.69e+03     |\n",
      "|    ep_rew_mean          | -5.9e+04     |\n",
      "|    success_rate         | 0.2          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 915          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 9728         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019163894 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.9         |\n",
      "|    explained_variance   | 8.08e-05     |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 3.92e+04     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 8.07e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -5.9e+04    |\n",
      "|    success_rate         | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 915         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 9984        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004855993 |\n",
      "|    clip_fraction        | 0.0223      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | 1.91e-05    |\n",
      "|    learning_rate        | 0.000999    |\n",
      "|    loss                 | 4.6e+04     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 9.12e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -5.9e+04    |\n",
      "|    success_rate         | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 913         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003184432 |\n",
      "|    clip_fraction        | 0.00469     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | -3e-05      |\n",
      "|    learning_rate        | 0.000999    |\n",
      "|    loss                 | 5.38e+04    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.05e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.74e+03     |\n",
      "|    ep_rew_mean          | -5.53e+04    |\n",
      "|    success_rate         | 0.167        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 913          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 10496        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018993164 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.98        |\n",
      "|    explained_variance   | 1.99e-05     |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 1.53e+05     |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 3.03e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | -5.53e+04   |\n",
      "|    success_rate         | 0.167       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 913         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 10752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001272101 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | -2.52e-05   |\n",
      "|    learning_rate        | 0.000999    |\n",
      "|    loss                 | 2.11e+05    |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 4.45e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.74e+03     |\n",
      "|    ep_rew_mean          | -5.53e+04    |\n",
      "|    success_rate         | 0.167        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 915          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 11008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012940355 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.98        |\n",
      "|    explained_variance   | 5.26e-05     |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 5.19e+04     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 1e+05        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.74e+03     |\n",
      "|    ep_rew_mean          | -5.53e+04    |\n",
      "|    success_rate         | 0.167        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 915          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 11264        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049985433 |\n",
      "|    clip_fraction        | 0.00898      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.96        |\n",
      "|    explained_variance   | 0.000136     |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 2.24e+04     |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 4.64e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.74e+03     |\n",
      "|    ep_rew_mean          | -5.53e+04    |\n",
      "|    success_rate         | 0.167        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 915          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 11520        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019668005 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.97        |\n",
      "|    explained_variance   | 0.000168     |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 2.03e+04     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 4.02e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.74e+03      |\n",
      "|    ep_rew_mean          | -5.53e+04     |\n",
      "|    success_rate         | 0.167         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 914           |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 12            |\n",
      "|    total_timesteps      | 11776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046984502 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.95         |\n",
      "|    explained_variance   | 1.21e-05      |\n",
      "|    learning_rate        | 0.000999      |\n",
      "|    loss                 | 2.61e+04      |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -0.00153      |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 5.34e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.69e+03     |\n",
      "|    ep_rew_mean          | -5e+04       |\n",
      "|    success_rate         | 0.286        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 914          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 12032        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012316441 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.95        |\n",
      "|    explained_variance   | 0.000111     |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 3.61e+04     |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 7.41e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -5e+04      |\n",
      "|    success_rate         | 0.286       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 913         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014671661 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | 2.53e-05    |\n",
      "|    learning_rate        | 0.000999    |\n",
      "|    loss                 | 1.67e+04    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 3.53e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.69e+03     |\n",
      "|    ep_rew_mean          | -5e+04       |\n",
      "|    success_rate         | 0.286        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 912          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 12544        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013643999 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.98        |\n",
      "|    explained_variance   | -2.01e-05    |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 2.95e+04     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 5.76e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.69e+03      |\n",
      "|    ep_rew_mean          | -5e+04        |\n",
      "|    success_rate         | 0.286         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 911           |\n",
      "|    iterations           | 50            |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 12800         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3153763e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.97         |\n",
      "|    explained_variance   | -3.81e-06     |\n",
      "|    learning_rate        | 0.000999      |\n",
      "|    loss                 | 4.79e+04      |\n",
      "|    n_updates            | 490           |\n",
      "|    policy_gradient_loss | -0.000319     |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 9.79e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.69e+03      |\n",
      "|    ep_rew_mean          | -5e+04        |\n",
      "|    success_rate         | 0.286         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 911           |\n",
      "|    iterations           | 51            |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 13056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7188252e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.97         |\n",
      "|    explained_variance   | 2.56e-06      |\n",
      "|    learning_rate        | 0.000999      |\n",
      "|    loss                 | 1.23e+05      |\n",
      "|    n_updates            | 500           |\n",
      "|    policy_gradient_loss | -0.00054      |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 2.42e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.69e+03      |\n",
      "|    ep_rew_mean          | -5e+04        |\n",
      "|    success_rate         | 0.286         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 911           |\n",
      "|    iterations           | 52            |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 13312         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.2183168e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.97         |\n",
      "|    explained_variance   | 1.02e-05      |\n",
      "|    learning_rate        | 0.000999      |\n",
      "|    loss                 | 2.49e+05      |\n",
      "|    n_updates            | 510           |\n",
      "|    policy_gradient_loss | -0.000489     |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 4.88e+05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.69e+03     |\n",
      "|    ep_rew_mean          | -5e+04       |\n",
      "|    success_rate         | 0.286        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 911          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 13568        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.456992e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.98        |\n",
      "|    explained_variance   | 2.34e-05     |\n",
      "|    learning_rate        | 0.000999     |\n",
      "|    loss                 | 3.06e+05     |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.000266    |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 6.19e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m reward_logger = training_module.RewardLoggerCallback(env, movie_save_freq=\u001b[38;5;28mint\u001b[39m(\u001b[32m5e5\u001b[39m), model_save_freq=\u001b[38;5;28mint\u001b[39m(\u001b[32m5e5\u001b[39m), verbose=\u001b[32m1\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Train the agent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[43mrl_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m10e6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreward_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPPO\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:311\u001b[39m, in \u001b[36mPPO.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    303\u001b[39m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[32m    304\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    309\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    310\u001b[39m ) -> SelfPPO:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:323\u001b[39m, in \u001b[36mOnPolicyAlgorithm.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_timesteps < total_timesteps:\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     continue_training = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[32m    326\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:202\u001b[39m, in \u001b[36mOnPolicyAlgorithm.collect_rollouts\u001b[39m\u001b[34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m th.no_grad():\n\u001b[32m    200\u001b[39m     \u001b[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[32m    201\u001b[39m     obs_tensor = obs_as_tensor(\u001b[38;5;28mself\u001b[39m._last_obs, \u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     actions, values, log_probs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m actions = actions.cpu().numpy()\n\u001b[32m    205\u001b[39m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:647\u001b[39m, in \u001b[36mActorCriticPolicy.forward\u001b[39m\u001b[34m(self, obs, deterministic)\u001b[39m\n\u001b[32m    645\u001b[39m features = \u001b[38;5;28mself\u001b[39m.extract_features(obs)\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.share_features_extractor:\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m     latent_pi, latent_vf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    649\u001b[39m     pi_features, vf_features = features\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:257\u001b[39m, in \u001b[36mMlpExtractor.forward\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: th.Tensor) -> \u001b[38;5;28mtuple\u001b[39m[th.Tensor, th.Tensor]:\n\u001b[32m    253\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[33;03m    :return: latent_policy, latent_value of the specified network.\u001b[39;00m\n\u001b[32m    255\u001b[39m \u001b[33;03m        If all layers are shared, then ``latent_policy == latent_value``\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forward_actor(features), \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_critic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:263\u001b[39m, in \u001b[36mMlpExtractor.forward_critic\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward_critic\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: th.Tensor) -> th.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalue_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\side_project\\mujoco\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import robot_env\n",
    "import training_module\n",
    "\n",
    "importlib.reload(robot_env)\n",
    "importlib.reload(training_module)\n",
    "importlib.reload(util)\n",
    "\n",
    "# Create the custom environment\n",
    "env = robot_env.ArmEnv(model_path='2dof_robot.xml')\n",
    "\n",
    "# Check the environment\n",
    "check_env(env)\n",
    "\n",
    "load_existing_model = False\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "if load_existing_model:\n",
    "    print(\"Loading existing model\")\n",
    "    rl_model = PPO.load(\"best_model.zip\", env=env)\n",
    "    rl_model.learning_rate = training_module.linear_schedule(learning_rate)\n",
    "else:\n",
    "    print('Creating new model')\n",
    "    rl_model = PPO(\n",
    "        \"MlpPolicy\", \n",
    "        env, \n",
    "        verbose=1, \n",
    "        tensorboard_log=\"./ppo_logs/\",\n",
    "        learning_rate=training_module.linear_schedule(learning_rate),\n",
    "        gamma=0.999,\n",
    "        policy_kwargs=dict(net_arch=[8, 8]),\n",
    "        n_steps=2**8,  # Collect more steps before updating policy\n",
    "        # batch_size=64,  # Mini-batch size for training\n",
    "        # n_epochs=10,  # More training passes per batch\n",
    "        # ,  # Discount factor\n",
    "        # gae_lambda=0.95,  # Smoother advantage estimation\n",
    "        # clip_range=0.2,  # Clipping parameter\n",
    "        # ent_coef=0.01,  # Encourages exploration\n",
    "        # vf_coef=0.5,  # Importance of value function loss\n",
    "        # max_grad_norm=0.5,  # Prevents exploding gradients\n",
    "        \n",
    "    )\n",
    "\n",
    "reward_logger = training_module.RewardLoggerCallback(env, movie_save_freq=int(5e5), model_save_freq=int(5e5), verbose=1)\n",
    "\n",
    "# Train the agent\n",
    "rl_model.learn(total_timesteps=int(10e6), callback=reward_logger, tb_log_name=\"PPO\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
